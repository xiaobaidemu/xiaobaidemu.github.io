<!DOCTYPE html>
<html lang="zh">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha256-CTSx/A06dm1B063156EVh15m6Y67pAjZZaQc89LLSrU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"xiaobaidemu.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.18.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="太长不想看全文，看这里-&gt;：1. CUDA runtime之于driver向后兼容原则，任何指定的CUDA版本都有一个与之对应的最小GPU driver版本。2.GPU的容器来说，容器中的CUDA版本受宿主机的GPU driver限制  &amp;emsp;&amp;emsp;虽然我并不研究深度学习的算法，但是作为相关训练平台的使用者和搭建者，很多同学都会问我这些问题。“我的训练镜像是用的pytorch是">
<meta property="og:type" content="article">
<meta property="og:title" content="从CUDA兼容性与GPU容器角度以及k8s深入掌控深度学习环境">
<meta property="og:url" content="http://xiaobaidemu.github.io/%E4%BB%8ECUDA%E5%85%BC%E5%AE%B9%E6%80%A7%E4%B8%8EGPU%E5%AE%B9%E5%99%A8%E8%A7%92%E5%BA%A6%E4%BB%A5%E5%8F%8Ak8s%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8E%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/index.html">
<meta property="og:site_name" content="xiaobaidemu">
<meta property="og:description" content="太长不想看全文，看这里-&gt;：1. CUDA runtime之于driver向后兼容原则，任何指定的CUDA版本都有一个与之对应的最小GPU driver版本。2.GPU的容器来说，容器中的CUDA版本受宿主机的GPU driver限制  &amp;emsp;&amp;emsp;虽然我并不研究深度学习的算法，但是作为相关训练平台的使用者和搭建者，很多同学都会问我这些问题。“我的训练镜像是用的pytorch是">
<meta property="og:locale">
<meta property="og:image" content="http://xiaobaidemu.github.io/%E4%BB%8ECUDA%E5%85%BC%E5%AE%B9%E6%80%A7%E4%B8%8EGPU%E5%AE%B9%E5%99%A8%E8%A7%92%E5%BA%A6%E4%BB%A5%E5%8F%8Ak8s%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8E%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/cuda_driver.jpg">
<meta property="og:image" content="http://xiaobaidemu.github.io/%E4%BB%8ECUDA%E5%85%BC%E5%AE%B9%E6%80%A7%E4%B8%8EGPU%E5%AE%B9%E5%99%A8%E8%A7%92%E5%BA%A6%E4%BB%A5%E5%8F%8Ak8s%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8E%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/cuda_runtime_structure.jpg">
<meta property="og:image" content="http://xiaobaidemu.github.io/%E4%BB%8ECUDA%E5%85%BC%E5%AE%B9%E6%80%A7%E4%B8%8EGPU%E5%AE%B9%E5%99%A8%E8%A7%92%E5%BA%A6%E4%BB%A5%E5%8F%8Ak8s%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8E%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/cuda10.1.jpg">
<meta property="og:image" content="http://xiaobaidemu.github.io/%E4%BB%8ECUDA%E5%85%BC%E5%AE%B9%E6%80%A7%E4%B8%8EGPU%E5%AE%B9%E5%99%A8%E8%A7%92%E5%BA%A6%E4%BB%A5%E5%8F%8Ak8s%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8E%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/cuda11_0.jpg">
<meta property="og:image" content="http://xiaobaidemu.github.io/%E4%BB%8ECUDA%E5%85%BC%E5%AE%B9%E6%80%A7%E4%B8%8EGPU%E5%AE%B9%E5%99%A8%E8%A7%92%E5%BA%A6%E4%BB%A5%E5%8F%8Ak8s%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8E%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/cuda11_2.jpg">
<meta property="og:image" content="http://xiaobaidemu.github.io/%E4%BB%8ECUDA%E5%85%BC%E5%AE%B9%E6%80%A7%E4%B8%8EGPU%E5%AE%B9%E5%99%A8%E8%A7%92%E5%BA%A6%E4%BB%A5%E5%8F%8Ak8s%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8E%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/cuda_table.jpg">
<meta property="og:image" content="http://xiaobaidemu.github.io/%E4%BB%8ECUDA%E5%85%BC%E5%AE%B9%E6%80%A7%E4%B8%8EGPU%E5%AE%B9%E5%99%A8%E8%A7%92%E5%BA%A6%E4%BB%A5%E5%8F%8Ak8s%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8E%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/devicequery.jpg">
<meta property="og:image" content="http://xiaobaidemu.github.io/%E4%BB%8ECUDA%E5%85%BC%E5%AE%B9%E6%80%A7%E4%B8%8EGPU%E5%AE%B9%E5%99%A8%E8%A7%92%E5%BA%A6%E4%BB%A5%E5%8F%8Ak8s%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8E%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/gpu_container.jpg">
<meta property="og:image" content="http://xiaobaidemu.github.io/%E4%BB%8ECUDA%E5%85%BC%E5%AE%B9%E6%80%A7%E4%B8%8EGPU%E5%AE%B9%E5%99%A8%E8%A7%92%E5%BA%A6%E4%BB%A5%E5%8F%8Ak8s%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8E%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/k8s_operator_structure.png">
<meta property="article:published_time" content="2023-10-17T08:51:36.000Z">
<meta property="article:modified_time" content="2023-10-18T03:41:22.648Z">
<meta property="article:author" content="xiaobaidemu">
<meta property="article:tag" content="kubernetes,devops,aigc">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://xiaobaidemu.github.io/%E4%BB%8ECUDA%E5%85%BC%E5%AE%B9%E6%80%A7%E4%B8%8EGPU%E5%AE%B9%E5%99%A8%E8%A7%92%E5%BA%A6%E4%BB%A5%E5%8F%8Ak8s%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8E%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/cuda_driver.jpg">


<link rel="canonical" href="http://xiaobaidemu.github.io/%E4%BB%8ECUDA%E5%85%BC%E5%AE%B9%E6%80%A7%E4%B8%8EGPU%E5%AE%B9%E5%99%A8%E8%A7%92%E5%BA%A6%E4%BB%A5%E5%8F%8Ak8s%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8E%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh","comments":true,"permalink":"http://xiaobaidemu.github.io/%E4%BB%8ECUDA%E5%85%BC%E5%AE%B9%E6%80%A7%E4%B8%8EGPU%E5%AE%B9%E5%99%A8%E8%A7%92%E5%BA%A6%E4%BB%A5%E5%8F%8Ak8s%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8E%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/","path":"从CUDA兼容性与GPU容器角度以及k8s深入掌控深度学习环境/","title":"从CUDA兼容性与GPU容器角度以及k8s深入掌控深度学习环境"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>从CUDA兼容性与GPU容器角度以及k8s深入掌控深度学习环境 | xiaobaidemu</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">xiaobaidemu</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">归档我的五年</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%85%88%E9%97%AE%E8%87%AA%E5%B7%B1%E4%B8%A4%E4%B8%AA%E9%97%AE%E9%A2%98"><span class="nav-number">1.</span> <span class="nav-text">先问自己两个问题</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5"><span class="nav-number">2.</span> <span class="nav-text">基础概念</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9B%9E%E7%AD%94%E4%B8%8A%E6%96%B9%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-number">3.</span> <span class="nav-text">回答上方的问题</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E5%BD%92%E6%A0%B9%E8%BF%98%E6%98%AFCUDA-Version-Driver-Version-%E5%85%BC%E5%AE%B9%E5%8E%9F%E5%88%99"><span class="nav-number">3.1.</span> <span class="nav-text">1. 归根还是CUDA Version&#x2F;Driver Version&#x2F;兼容原则</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%BC%E5%AE%B9%E6%80%A7%E5%8E%9F%E5%88%99%E4%B8%80%EF%BC%9A%E6%BA%90%E7%A0%81%E7%BA%A7%E5%88%AB%E4%B8%8D%E5%85%BC%E5%AE%B9%E6%80%A7"><span class="nav-number">3.1.1.</span> <span class="nav-text">兼容性原则一：源码级别不兼容性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%BC%E5%AE%B9%E5%8E%9F%E5%88%99%E4%BA%8C%EF%BC%9A%E5%90%8E%E5%90%91%E5%85%BC%E5%AE%B9"><span class="nav-number">3.1.2.</span> <span class="nav-text">兼容原则二：后向兼容</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%BC%E5%AE%B9%E5%8E%9F%E5%88%99%E4%B8%89%EF%BC%9A%E6%9C%89%E9%99%90%E7%9A%84%E5%89%8D%E5%90%91%E5%85%BC%E5%AE%B9"><span class="nav-number">3.1.3.</span> <span class="nav-text">兼容原则三：有限的前向兼容</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%BC%E5%AE%B9%E6%80%A7%E5%8E%9F%E5%88%99%E5%9B%9B%EF%BC%9Acuda%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E7%BC%96%E8%AF%91%E4%BA%A7%E7%89%A9%E4%B8%8E%E4%B8%8D%E5%90%8CGPU%E6%9E%B6%E6%9E%84%E9%97%B4%E7%9A%84%E5%85%BC%E5%AE%B9"><span class="nav-number">3.1.4.</span> <span class="nav-text">兼容性原则四：cuda应用程序编译产物与不同GPU架构间的兼容</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E5%BD%92%E6%A0%B9%E8%BF%98%E6%98%AF%E5%AE%B9%E5%99%A8%E4%B8%AD%E2%80%9D%E6%8C%82%E8%BD%BD%E2%80%9D%E5%AE%BF%E4%B8%BB%E6%9C%BA%E7%9A%84%E2%80%9D%E6%96%87%E4%BB%B6%E2%80%9D"><span class="nav-number">3.2.</span> <span class="nav-text">2. 归根还是容器中”挂载”宿主机的”文件”</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9B%9E%E5%88%B0%E8%AE%AD%E7%BB%83%E5%B9%B3%E5%8F%B0"><span class="nav-number">4.</span> <span class="nav-text">回到训练平台</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9C%A8%E8%AE%AD%E7%BB%83%E5%B9%B3%E5%8F%B0%E4%B8%AD%E8%AE%AD%E7%BB%83%E4%BB%BB%E5%8A%A1"><span class="nav-number">4.1.</span> <span class="nav-text">在训练平台中训练任务</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%99%84%E5%BD%95"><span class="nav-number">5.</span> <span class="nav-text">附录</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">xiaobaidemu</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">3</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">categories</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh">
    <link itemprop="mainEntityOfPage" href="http://xiaobaidemu.github.io/%E4%BB%8ECUDA%E5%85%BC%E5%AE%B9%E6%80%A7%E4%B8%8EGPU%E5%AE%B9%E5%99%A8%E8%A7%92%E5%BA%A6%E4%BB%A5%E5%8F%8Ak8s%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8E%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="xiaobaidemu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="xiaobaidemu">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="从CUDA兼容性与GPU容器角度以及k8s深入掌控深度学习环境 | xiaobaidemu">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          从CUDA兼容性与GPU容器角度以及k8s深入掌控深度学习环境
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-10-17 16:51:36" itemprop="dateCreated datePublished" datetime="2023-10-17T16:51:36+08:00">2023-10-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-18 11:41:22" itemprop="dateModified" datetime="2023-10-18T11:41:22+08:00">2023-10-18</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><blockquote>
<p>太长不想看全文，看这里-&gt;：1. CUDA runtime之于driver向后兼容原则，任何指定的CUDA版本都有一个与之对应的最小GPU driver版本。2.GPU的容器来说，容器中的CUDA版本受宿主机的GPU driver限制</p>
</blockquote>
<p>&emsp;&emsp;虽然我并不研究深度学习的算法，但是作为相关训练平台的使用者和搭建者，很多同学都会问我这些问题。“我的训练镜像是用的pytorch是cuda11的，那我的任务在如何才能分配到一台支持cuda11的GPU容器中”，”我使用训练平台1和训练平台2训练任务（因为公司内部有两个完全训练平台，这里分别用1和2表示），可是同样的镜像和代码，在平台2可以正常运行，但是平台1有的时候运行出错”。说真的每次碰到这种问题，我头很大，我不知道应该从什么地方说起，本文就是从一个新手的视角出发，并从兼容性原则和容器方向说说，这些运行时环境相关的问题是怎么决定我们的代码运行的。</p>
<h1 id="先问自己两个问题"><a href="#先问自己两个问题" class="headerlink" title="先问自己两个问题"></a>先问自己两个问题</h1><ol>
<li>nvidia-smi命令中返回的CUDA Version和Driver Version的关系，以及和我运行机器&#x2F;镜像中的安装的cuda库版本之间的关系？</li>
</ol>
<p><img src="/%E4%BB%8ECUDA%E5%85%BC%E5%AE%B9%E6%80%A7%E4%B8%8EGPU%E5%AE%B9%E5%99%A8%E8%A7%92%E5%BA%A6%E4%BB%A5%E5%8F%8Ak8s%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8E%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/cuda_driver.jpg" alt="图1"></p>
<ol start="2">
<li>在容器(例如使用docker创建的容器)中通过GPU训练，容器镜像到底需要安装什么？镜像中需要安装GPU驱动吗？</li>
</ol>
<p>&emsp;&emsp;我认为很多的由于训练环境导致的训练异常，都可以从这两个问题的回答中找到原因，进而更快的定位异常点。下面我围绕这两个问题，详细的做一个回答。</p>
<h1 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h1><p>&emsp;&emsp;CUDA本质上就是NVIDIA专为通用高性能并行计算设计的一套计算平台和编程模型，换句话使用GPU并行编程的规范方法，所以CUDA在软件层面包含了众多库， 那这里我们用一张图来简单阐述CUDA的各类运行时以及库的关系。</p>
<p><img src="/%E4%BB%8ECUDA%E5%85%BC%E5%AE%B9%E6%80%A7%E4%B8%8EGPU%E5%AE%B9%E5%99%A8%E8%A7%92%E5%BA%A6%E4%BB%A5%E5%8F%8Ak8s%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8E%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/cuda_runtime_structure.jpg" alt="图2"></p>
<p>&emsp;&emsp;从最底层开始CUDA Driver（也就是常说的GPU驱动）：可以认为是最底层的操作GPU的接口，作为直接与GPU设备打交道，其编程难度很大，但是性能更好。而CUDA Runtime（也就是常说的CUDA库）：更多是面向CUDA应用开发人员，其API更加简化，可编程性更高，而基于CUDA Runtime接口再向上封装了更多的面向专用计算场景的库，例如专用于深度学习的cuDNN库等。最后，应用层可以使用CUDA Library或者直接使用CUDA Runtime API实现其功能。</p>
<p>&emsp;&emsp;我们都知道想要使用GPU训练程序，那么必须要从nividia官方选择安装对应GPU机型的驱动文件。而官方提供的是一个叫做CUDA toolkit打包的东西，这个本质上是CUDA相关库和工具的集合，例如你如果选择<a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#runfile">runfile方式安装</a>，从官方下载下来的run文件（eg：cuda_11.0.3_450.51.06_linux.run），本身其中包括了CUDA Runtime（CUDA库），CUDA Driver （GPU驱动），还有样例代码，用户可以通过命令选择，需要安装CUDA库还是GPU驱动，还是说两者都安装。</p>
<p>&emsp;&emsp;另外nvidia-smi本质上是直接使用CUDA driver库，所以说和系统中安装的CUDA Runtime（即CUDA版本）无关.</p>
<h1 id="回答上方的问题"><a href="#回答上方的问题" class="headerlink" title="回答上方的问题"></a>回答上方的问题</h1><h2 id="1-归根还是CUDA-Version-Driver-Version-兼容原则"><a href="#1-归根还是CUDA-Version-Driver-Version-兼容原则" class="headerlink" title="1. 归根还是CUDA Version&#x2F;Driver Version&#x2F;兼容原则"></a>1. 归根还是CUDA Version&#x2F;Driver Version&#x2F;兼容原则</h2><p>&emsp;&emsp;本质上第一个问题，回答的就是上述驱动和CUDA运行时库之间的兼容性的问题。</p>
<p>&emsp;&emsp;nvidia-smi中显示的CUDA Version本质上是DRIVER API COMPATIBILITY VERSION，换句话理解就是<font color=red>根据机器上当前GPU的Driver驱动版本，CUDA Version显示的是与驱动匹配的最高兼容的CUDA Runtime版本</font>（下文都我们简称CUDA Runtime为CUDA，简单理解就是你可以在机器中安装的cuda动态&#x2F;静态链接库的最高版本，CUDA driver简称为driver或驱动）。下面从源码&#x2F;二进制&#x2F;cubin三个角度具体说说兼容性，这有助于更好的排查“为什么我的训练代码在这台机器上跑不起来”的问题。</p>
<h3 id="兼容性原则一：源码级别不兼容性"><a href="#兼容性原则一：源码级别不兼容性" class="headerlink" title="兼容性原则一：源码级别不兼容性"></a>兼容性原则一：源码级别不兼容性</h3><p>&emsp;&emsp;所谓源码不兼容很好理解，例如用户的代码是基于cuda 10.1这一特定版本对应的API库构建的，那么如果用户升级到cuda11.0的对应API库，则可能无法正常运行。需要用户根据cuda11.0对应的API文档修改代码再进行编译构建。所以我们可以看到pytorch，针对不同的cuda版本，都有对应不同的编译后的库，例如下面两个就是分别基于cuda11.1（<a target="_blank" rel="noopener" href="https://download.pytorch.org/whl/cu113/torch-1.10.1%2Bcu113-cp37-cp37m-linux_x86_64.whl">torch-1.10.1%2Bcu113-cp37-cp37m-linux_x86_64.whl</a>）和cuda11.3（<a target="_blank" rel="noopener" href="https://download.pytorch.org/whl/cu111/torch-1.10.0%2Bcu111-cp36-cp36m-linux_x86_64.whl">torch-1.10.0%2Bcu111-cp36-cp36m-linux_x86_64.whl</a>）不同的cuda版本构建的。</p>
<h3 id="兼容原则二：后向兼容"><a href="#兼容原则二：后向兼容" class="headerlink" title="兼容原则二：后向兼容"></a>兼容原则二：后向兼容</h3><p>&emsp;&emsp;后向兼容的意思是：如果一个程序使用的CUDA版本可以在某一Driver版本下运行，那么在升级了Driver后，此程序在保持原CUDA版本的情况下，仍然可以在新的更高版本的驱动下运行。换句话说，某一具体的cuda版本存在与之对应的最小驱动版本。而对于cuda11和cuda10这两个主版本下，兼容的情况也有细微的却别。兼容性对照表可以查看。</p>
<p>&emsp;&emsp;<font color=red>1. 对于cuda11主版本 </font>（cuda版本是X.Y.X三段式，其中X为主版本号，Y为次版本号），那么对于以11开头的所有CUDA版本来说，只要driver版本&gt;&#x3D;450.80.02*, 则即可满足所有的CUDA11.0,11.1,11.2等以11.x开头的CUDA运行时版本。这种兼容模式称作为为次版本兼容（Minor Version Compatibility）。当然这种兼容是“limited feature-set”，换句话说满足在保持驱动不变下，升级cuda版本后，运行不出错，但是对于一些高版本的cuda的特性，如果要更好的使用或者性能，也需要升级driver驱动。比如对于cuda11.2，官方的cuda toolkit包中推荐安装的driver是&gt;&#x3D;460.00。</p>
<p>&emsp;&emsp;回到上面的问题1，我们用的云开发GPU是一个vGPU实例，把Tesla T4 从一个GPU虚拟化出两个vGPU分配给两台虚拟机，nvidia-smi显示Driver Version为450.102.04，而CUDA Version显示的是11.0，通过上文的说明，可以发现此虚拟机支持包括11.x在内的所有cuda11版本，而CUDA Version显示的可以认为是最高兼容的CUDA“主版本”。这里验证的方法也很简单，可以在云开发GPU机器中安装任意的cuda10.x&#x2F;cuda11.x，通过编译cuda sampler示例中的deviceQuery程序验证。</p>
<table>
<thead>
<tr>
<th>cuda10.1</th>
<th>cuda11.0</th>
<th>cuda11.2</th>
</tr>
</thead>
<tbody><tr>
<td><img src="/%E4%BB%8ECUDA%E5%85%BC%E5%AE%B9%E6%80%A7%E4%B8%8EGPU%E5%AE%B9%E5%99%A8%E8%A7%92%E5%BA%A6%E4%BB%A5%E5%8F%8Ak8s%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8E%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/cuda10.1.jpg" alt="cuda10.1"></td>
<td><img src="/%E4%BB%8ECUDA%E5%85%BC%E5%AE%B9%E6%80%A7%E4%B8%8EGPU%E5%AE%B9%E5%99%A8%E8%A7%92%E5%BA%A6%E4%BB%A5%E5%8F%8Ak8s%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8E%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/cuda11_0.jpg" alt="cuda11.0"></td>
<td><img src="/%E4%BB%8ECUDA%E5%85%BC%E5%AE%B9%E6%80%A7%E4%B8%8EGPU%E5%AE%B9%E5%99%A8%E8%A7%92%E5%BA%A6%E4%BB%A5%E5%8F%8Ak8s%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8E%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/cuda11_2.jpg" alt="cuda11.2"></td>
</tr>
</tbody></table>
<p>&emsp;&emsp;<font color=red>2. 对于cuda10这主版本</font>，每一个cuda10.x的版本都有与之对应的最小驱动版本号，例如下图是截取自<a target="_blank" rel="noopener" href="https://docs.nvidia.com/deploy/cuda-compatibility/">CUDA Compatibility :: NVIDIA Data Center GPU Driver Documentation</a>。可以看到cuda10.0&#x2F;10.1&#x2F;10.2对应的最小满足的版本号均不一样，不同于cuda11.x，可以在驱动不变的情况下升级cuda，cuda10.x，想要升级从10.1升级到10.2，那么驱动版本必须要大于等于440.33。<br><img src="/%E4%BB%8ECUDA%E5%85%BC%E5%AE%B9%E6%80%A7%E4%B8%8EGPU%E5%AE%B9%E5%99%A8%E8%A7%92%E5%BA%A6%E4%BB%A5%E5%8F%8Ak8s%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8E%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/cuda_table.jpg" alt="cuda_table"></p>
<p>&emsp;&emsp;当我们公司的训练平台1创建一个”所谓的”cuda_version版本为10.2的任务，那么分配给我们的机器对应的driver版本号为440.64.00，那么假如我们安装cuda11.2，则显而易见编译后运行上文的deviceQuery程序会返回错误。</p>
<p><img src="/%E4%BB%8ECUDA%E5%85%BC%E5%AE%B9%E6%80%A7%E4%B8%8EGPU%E5%AE%B9%E5%99%A8%E8%A7%92%E5%BA%A6%E4%BB%A5%E5%8F%8Ak8s%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8E%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/devicequery.jpg" alt="device_query"></p>
<p>&emsp;&emsp;而对于GPU来说，虚拟机中的驱动都是450.102.04，因此可以支持任意cuda11及以下的CUDA Runtime。</p>
<h3 id="兼容原则三：有限的前向兼容"><a href="#兼容原则三：有限的前向兼容" class="headerlink" title="兼容原则三：有限的前向兼容"></a>兼容原则三：有限的前向兼容</h3><p>&emsp;&emsp;后向兼容是需要在cuda升级后，驱动也需要根据要求进行升级（或者不变）。而前向兼容的意思就是，在cuda升级后，driver不需要对内核态相关包进行升级，而只需要变更相关用户态文件即可。目的就是可以在老旧驱动上基于新的cuda版本编译程序，从而获取到最新的cuda特性。 而为什么说是有限的兼容，主要表现在两点限制：1. 限制了GPU卡的类型，只有NVIDIA Data Center&#x2F;Tesla 系列（和小部分特殊的RTX）的GPU卡. 2. 前向兼容的能力理论上只有在需要跨cuda主版本的时使用，例如本来最高只支持cuda版本10.1的Driver418，可以通过安装正确的Compat Package,使其在不更新内核态驱动的情况，支持cuda10.1~cuda11.6。具体可以参考官方文档的前向兼容矩阵，来下载安装对应的兼容包。<a target="_blank" rel="noopener" href="https://docs.nvidia.com/deploy/cuda-compatibility/">CUDA Compatibility :: NVIDIA Data Center GPU Driver Documentation</a></p>
<h3 id="兼容性原则四：cuda应用程序编译产物与不同GPU架构间的兼容"><a href="#兼容性原则四：cuda应用程序编译产物与不同GPU架构间的兼容" class="headerlink" title="兼容性原则四：cuda应用程序编译产物与不同GPU架构间的兼容"></a>兼容性原则四：cuda应用程序编译产物与不同GPU架构间的兼容</h3><p>&emsp;&emsp;这部分的兼容性原则理解起来，需要涉及到cuda应用程序编译的相关知识。一个写好的cuda程序，通过nvcc编译后的产物可以包含两种形式，一个是二进制的cubin对象，另一个是PTX（Parallel Thread Execution）汇编代码。</p>
<p>&emsp;&emsp;cubin是特定于指定的GPU架构的，cubin二进制对象对于GPU架构的计算能力（计算能力只是代表一个GPU的能力特性与性能高低无关）是一个向后兼容的，并且对GPU计算能力也是类似Minor Version Compatibility，换句话说，为计算能力为X.y的GPU生成的cubin对象，只能在计算能力为X.z且z&gt;&#x3D;y的GPU上运行。举个例子：为7.0计算能力生成的cubin，可以在7计算能力为7.5的GPU上执行，但是无法在计算能力为8.0的GPU上执行。</p>
<p>&emsp;&emsp;那对于编译成PTX形式的产物，在cuda应用程序运行加载时，会先由设备驱动程序进一步把PTX通过JIT技术（即时编译）编译成对应GPU架构或者计算能力的cubin，这也就意味着此PTX可以在计算能力高于当前生成的此PTX计算能力的GPU上运行。关于更多JIT的内容可以参考：<a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#just-in-time-compilation">Programming Guide :: CUDA Toolkit Documentation</a></p>
<p>&emsp;&emsp;因此，如果一个cuda应用程序在编译时选择包含PTX相关产物，“理论上”可以更好的保证在GPU架构升级后，代码仍然可以兼容运行，换句话说，”理论”上一个原先使用cuda10.x编译且可以在Volta架构V100上运行的应用，选择选择生成PTX二进制代码，那么可以在Ampere架构的A100上运行。</p>
<p>&emsp;&emsp;但是回到一个具体的案例，事实上对于pytorch，由于受制于使用的cuDNN与GPU架构升级的兼容的原因（cuDNN7与Ampere架构不兼容），以及pytorch使用pip wheel安装或者conda安装（pytorch在编译过程根据不同的安装方式会选择不同的编译模式，例如conda安装会选择使用包含PTX的二进制版本，而pip wheel安装可能不会包含），想要使用A100机器训练，必须升级到cuda11且cuDNN8以上版本的pytorch来可以使用。</p>
<p>&emsp;&emsp;换句话说，GPU的架构在一定程度上限制了cuda的版本（注：计算能力只是代表一个GPU的能力特性与性能高低无关）关于更多关于编译链接的内容，可以参考官网文档：<a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html">NVCC :: CUDA Toolkit Documentation</a></p>
<h2 id="2-归根还是容器中”挂载”宿主机的”文件”"><a href="#2-归根还是容器中”挂载”宿主机的”文件”" class="headerlink" title="2. 归根还是容器中”挂载”宿主机的”文件”"></a>2. 归根还是容器中”挂载”宿主机的”文件”</h2><p>&emsp;&emsp;要回答第二个问题，其实就是理解我们训练时候容器中CUDA 运行时所用的GPU驱动（或者说是CUDA driver API）到底是宿主机的驱动文件还是镜像中的驱动文件。这里可以用云开发GPU机器上的docker来作为观察对象。</p>
<p>&emsp;&emsp;我使用的云开发GPU机器中已经安装了的docker，事实上是把原来底层用来通过操作系统调用创建运行容器的“runc”组件替换为nvidia-container-runtime组件（关于runC的一些概念，可以参考之前的<a href="./%E4%BB%8Ekubernetes%E4%B8%AD%E5%AE%B9%E5%99%A8%E7%94%9F%E6%80%81%E7%AA%A5%E6%8E%A2%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%93%B2%E5%AD%A6.html">从kubernetes中容器生态窥探设计模式的哲学</a>），当然nvidia-contianer-runtime本质上是一个做了修改后的runc组件，区别是它增加了一个自定义的prestart hook，目的是在创建容器后，在启动容器前，调用这个hook，而这个hook本身做的就是一些类似将宿主机的device&#x2F;driver文件等挂载进容器中。下图为NVIDIA官网介绍NVIDIA Container的大致架构组件图。<br><img src="/%E4%BB%8ECUDA%E5%85%BC%E5%AE%B9%E6%80%A7%E4%B8%8EGPU%E5%AE%B9%E5%99%A8%E8%A7%92%E5%BA%A6%E4%BB%A5%E5%8F%8Ak8s%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8E%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/gpu_container.jpg" alt="gpu_container"></p>
<p>&emsp;&emsp;那到底具体将宿主机的哪些设备文件挂载进了容器呢。我们可以打开nvidia-container-runtime的debug功能，详细在其日志中查看所有文件设备挂载列表，具体为修改&#x2F;etc&#x2F;nvidia-container-runtime&#x2F;config.toml文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[nvidia-container-cli]</span><br><span class="line">environment = []</span><br><span class="line">debug = &quot;/var/log/nvidia-container-toolkit.log&quot;</span><br><span class="line">load-kmods = true</span><br><span class="line">ldconfig = &quot;@/sbin/ldconfig&quot;</span><br><span class="line">[nvidia-container-runtime]</span><br><span class="line">debug = &quot;/var/log/nvidia-container-runtime.log&quot;</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;打开debug功能后，我们重新通过docker 启动一个容器</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run  --rm --gpus &#x27;&quot;device=0&quot;&#x27; --net host  -it mirrors.tencent.com/shadow_test_xiaobaihe/test_for_light:torch_ptx /bin/bash</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;启动成功后，我们发现可以使用nvidia-smi命令查看挂载进容器的GPU情况。明明我的镜像中没有nvidia-smi这个二进制程序，为什么启动后文件就可以直接使用呢？那么秘密事实上就在nvidia-container-toolkit这个prehook内帮我们完成了。打开上方的&#x2F;var&#x2F;log&#x2F;nvidia-container-toolkit.log文件，可以详细的查询到整个hook过程。</p>
<p>&emsp;&emsp;其中我们发现，hook过程中向容器中注入了包括宿主机的二进制工具，例如nivida-smi&#x2F;nvida-debugdump等，宿主机的上的库，例如很重要的CUDA Driver API库libcuda.so。另外还有很重要的是在宿主机中通过mknod创建所需的nvidia相关的设备文件，并将宿主机的文件设备文件注入到容器中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 注入宿主机的二进制程序</span><br><span class="line"></span><br><span class="line">I0311 03:09:13.228302 19802 nvc_mount.c:112] mounting /usr/bin/nvidia-smi at /data/dockerimages/overlay2/05f25c9dde0a3cad98c5ec03e78fbd25ce10eb4ac52aeccac393d6645220770f/merged/usr/bin/nvidia-smi</span><br><span class="line">I0311 03:09:13.228326 19802 nvc_mount.c:112] mounting /usr/bin/nvidia-debugdump at /data/dockerimages/overlay2/05f25c9dde0a3cad98c5ec03e78fbd25ce10eb4ac52aeccac393d6645220770f/merged/usr/bin/nvidia-debugdump</span><br><span class="line"></span><br><span class="line"># 注入宿主机的CUDA Driver库</span><br><span class="line"></span><br><span class="line">I0311 03:09:13.228463 19802 nvc_mount.c:112] mounting /usr/lib64/libcuda.so.450.102.04 at /data/dockerimages/overlay2/05f25c9dde0a3cad98c5ec03e78fbd25ce10eb4ac52aeccac393d6645220770f/merged/usr/lib64/libcuda.so.450.102.04</span><br><span class="line">I0311 03:09:13.228484 19802 nvc_mount.c:112] mounting /usr/lib64/libnvidia-opencl.so.450.102.04 at /data/dockerimages/overlay2/05f25c9dde0a3cad98c5ec03e78fbd25ce10eb4ac52aeccac393d6645220770f/merged/usr/lib64/libnvidia-opencl.so.450.102.04</span><br><span class="line"></span><br><span class="line"># 创建设备文件，并将宿主机设备文件注入到容器中</span><br><span class="line"></span><br><span class="line">I0311 03:09:13.207136 19807 nvc.c:282] running mknod for /dev/nvidia0</span><br><span class="line">I0311 03:09:13.228019 19802 nvc_info.c:705] listing device /dev/nvidia0 (GPU-40143293-c4ff-11eb-ba91-04c440212a27 at 000000    00:00:09.0)</span><br><span class="line">I0311 03:09:13.280933 19802 nvc_mount.c:208] mounting /dev/nvidia0 at /data/dockerimages/overlay2/05f25c9dde0a3cad98c5ec03e    78fbd25ce10eb4ac52aeccac393d6645220770f/merged/dev/nvidia0</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;由此可以看到在使用nvidia-contiainer-runtime这种容器使用GPU的解决方案方案下，容器中使用CUDA Driver还有nvidia-smi都是来自于宿主机的，不需要在镜像中安装CUDA Driver。而如果在镜像中包含了CUDA driver库，可能会导致容器在hook过程中，在建立libcuda.so软链时，使用镜像中的driver库，从而可能触发上文说的”前向兼容”流程（即有可能镜像中使用的用户态的driver驱动高于宿主机的内核态的启动，从而使得GPU认为应该用前向兼容），而往往前向兼容是比较有限的，受制于GPU机型，还有驱动版本等，从而导致报错，例如可能出现forwoard compatibilty报错。</p>
<h1 id="回到训练平台"><a href="#回到训练平台" class="headerlink" title="回到训练平台"></a>回到训练平台</h1><p>&emsp;&emsp;根据第二个问题的答案，这就是为什么我们在各种平台训练的时候，镜像中都只需要打包CUDA Runtime和CUDA Libraries即可，而不需要存在驱动的相关库。因为训练容器使用的本身是宿主机上的驱动库。</p>
<p>&emsp;&emsp;而至于为什么同样的镜像和代码，在平台2可以正常运行，但是在平台1有的时候运行出错。这主要是因为不同平台所处集群中的机器驱动并不都是最新的，有一些机器驱动还是440只能到最高支持cuda10.2，而有的机器的驱动已经是450，可以支持到cuda11.x，而根据上文说的兼容性原则，如果镜像中使用的CUDA runtime库是cuda11，而实际上平台分配到的机器驱动只有440，那么根据上述的向后兼容原则，肯定是不行的，所以需要在训练平台1中强制指定cuda_version参数为11.0。平台2总是支持的原因，也在于其GPU宿主机的机器驱动比较新，都是支持cuda11.x的。</p>
<h2 id="在训练平台中训练任务"><a href="#在训练平台中训练任务" class="headerlink" title="在训练平台中训练任务"></a>在训练平台中训练任务</h2><p>&emsp;&emsp;现在往往大多数公司的训练平台都是基于kubernetes平台所搭建的，甚至在一个公司内部下的GPU集群是由多个k8s集群所组成的，在其之上，不同部门都会搭建自己不同的训练平台。例如本例中的平台1和平台2，其算力都来自于最底层的k8s集群。不同的训练平台，可以看做是不同的k8s租户，通过不同的的方案，来实现一个训练任务的资源创建。</p>
<p>&emsp;&emsp;在一年前，大模型还没有像如今这么繁荣的情况下，主要使用的k8s中的<a target="_blank" rel="noopener" href="https://www.redhat.com/zh/topics/containers/what-is-a-kubernetes-operator">Operator</a>来定制我们训练任务的多机多卡Pod以及网络的等组合方式，使用kubeflow&#x2F;mpi-operator方式，来创建满足all-reduce方式的通用任务。通过mpi-operator并配合k8s的CRD（CRD–custom resource definition）来引用MPIJob这个新的对象类型，换句话说训练平台在创建一个任务后通过Operator创建对应CR(custom resource)进行调度。这种方法更接近与云原生的kubeflow，同事可以通过Operator方式，扩展使用Pytorch-Operator&#x2F;Tensorflow-Operator等（目前的mpi-operator服务于类horovod并行训练）。<br><img src="/%E4%BB%8ECUDA%E5%85%BC%E5%AE%B9%E6%80%A7%E4%B8%8EGPU%E5%AE%B9%E5%99%A8%E8%A7%92%E5%BA%A6%E4%BB%A5%E5%8F%8Ak8s%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8E%A7%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/k8s_operator_structure.png" alt="k8s_operator"></p>
<h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><ol>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/deploy/cuda-compatibility/">CUDA Compatibility :: NVIDIA Data Center GPU Driver Documentation</a></li>
<li><a target="_blank" rel="noopener" href="https://forums.developer.nvidia.com/t/how-to-use-cuda-compatibility-package-to-use-a-newer-driver-on-an-older-kernel-module/77533/4">https://forums.developer.nvidia.com/t/how-to-use-cuda-compatibility-package-to-use-a-newer-driver-on-an-older-kernel-module/77533/4</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#cuda-compatibility-and-upgrades">Best Practices Guide :: CUDA Toolkit Documentation</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/arch-overview.html#arch-overview">Architecture Overview &mdash; NVIDIA Cloud Native Technologies documentation</a></li>
</ol>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/%E4%BB%8Ekubernetes%E4%B8%AD%E5%AE%B9%E5%99%A8%E7%94%9F%E6%80%81%E7%AA%A5%E6%8E%A2%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%93%B2%E5%AD%A6/" rel="prev" title="从kubernetes中容器生态窥探设计模式的哲学">
                  <i class="fa fa-angle-left"></i> 从kubernetes中容器生态窥探设计模式的哲学
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/%E6%89%8B%E6%8A%8A%E6%89%8B%E4%B8%80%E8%B5%B7DEBUG-Kubernetes-%E7%AC%AC%E4%B8%80%E7%AF%87-%E5%BB%BA%E7%AB%8Bk8s%E7%9A%84DEBUG%E7%8E%AF%E5%A2%83/" rel="next" title="手把手一起DEBUG Kubernetes(第一篇:建立k8s的DEBUG环境)">
                  手把手一起DEBUG Kubernetes(第一篇:建立k8s的DEBUG环境) <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2023</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">xiaobaidemu</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  






  





</body>
</html>
